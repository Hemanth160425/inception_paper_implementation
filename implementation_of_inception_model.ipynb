{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNynN2Mf4VcAPwfChau9/y9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemanth160425/inception_paper_implementation/blob/main/implementation_of_inception_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjQRA6ttO355"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class INCEPTION(nn.Module):\n",
        "  def __init__(self,cha_in,cha_out):\n",
        "    super().__init__()\n",
        "    self.relu=nn.ReLU()\n",
        "    self.p1=nn.Sequential(nn.Conv2d(cha_in,cha_out[0],stride=1,kernel_size=1,padding=0),self.relu)\n",
        "    self.p2=nn.Sequential(nn.Conv2d(cha_in,cha_out[1],stride=1,kernel_size=1,padding=0)\n",
        "             ,self.relu,nn.Conv2d(cha_out[1],cha_out[2],stride=1,kernel_size=3,padding=1),self.relu)\n",
        "    self.p3=nn.Sequential(nn.Conv2d(cha_in,cha_out[3],stride=1,kernel_size=1,padding=0)\n",
        "            ,self.relu,nn.Conv2d(cha_out[3],cha_out[4],stride=1,kernel_size=5,padding=2),self.relu)\n",
        "    self.p4=  nn.Sequential(nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
        "                            nn.Conv2d(cha_in,cha_out[5],stride=1,kernel_size=1,padding=0),self.relu)\n",
        "    def forward(self,x):\n",
        "      o1=self.p1(x)\n",
        "      o2=self.p2(x)\n",
        "      o3=self.p3(x)\n",
        "      o4=self.p4(x)\n",
        "      return torch.cat([o1,o2,o3,o4],1)"
      ],
      "metadata": {
        "id": "L2TzyQwVwRfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Auxclassifier(nn.Module):\n",
        "    def __init__(self, cha_in, cha_out):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "        self.conv = nn.Conv2d(cha_in, 128, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        # Using dropout and fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 1024)  # Adjust based on expected flattened size after pooling\n",
        "        self.fc2 = nn.Linear(1024, cha_out)\n",
        "        self.drop = nn.Dropout(0.7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)  # Apply average pooling\n",
        "        x = self.relu(self.conv(x))  # Apply conv + relu\n",
        "        x = torch.flatten(x, 1)  # Flatten the tensor, keep batch dimension\n",
        "        x = self.relu(self.drop(self.fc1(x)))  # Fully connected layer with dropout and ReLU\n",
        "        x = self.fc2(x)  # Final fully connected layer (no activation needed here)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "eetzB7_vHMKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class INCEPTIONV1(nn.Module):\n",
        "    def __init__(self, in_channel, features_map, classes):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([INCEPTION(in_channel[i], features_map[i]) for i in range(len(in_channel))])\n",
        "\n",
        "        self.aux1 = Auxclassifier(512, classes)\n",
        "        self.aux2 = Auxclassifier(528, classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.c1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.c2 = nn.Conv2d(64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "        self.c3 = nn.Conv2d(64, out_channels=192, kernel_size=3, stride=1, padding=1)\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "        self.fc = nn.Linear(1024, classes)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.localnorm = nn.LocalResponseNorm(size=5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = []\n",
        "        x = self.relu(self.c1(x))\n",
        "        x = self.localnorm(self.Maxpool(x))\n",
        "        x = self.relu(self.c2(x))\n",
        "        x = self.relu(self.c3(x))\n",
        "        x = self.Maxpool(self.localnorm(x))\n",
        "\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            if i == 2 or i == 7:  # Corrected the condition\n",
        "                x = self.Maxpool(x)\n",
        "            x = block(x)\n",
        "            if i == 3:\n",
        "                output.append(self.aux1(x))\n",
        "            if i == 6:\n",
        "                output.append(self.aux2(x))\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        output.append(x)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "CgGe91dOKGpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "in_channels = [192, 256, 480, 512, 512, 512, 528, 832, 832, 1024]\n",
        "feature_maps = [[64, 96, 128, 16, 32, 32],\n",
        "                        [128, 128, 192, 32, 96, 64],\n",
        "                        [192, 96, 208, 16, 48, 64],\n",
        "                        [160, 112, 224, 24, 64, 64],\n",
        "                        [128, 128, 256, 24, 64, 64],\n",
        "                        [112, 144, 288, 32, 64, 64],\n",
        "                        [256, 160, 320, 32, 128, 128],\n",
        "                        [256, 160, 320, 32, 128, 128],\n",
        "                        [384, 192, 384, 48, 128, 128]\n",
        "                    ]\n",
        "inception=INCEPTIONV1(in_channels,feature_maps,1000)\n",
        "inception(torch.rand(16,3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Eyu7HtWvbaMO",
        "outputId": "f6923826-8d2d-4dda-d334-61d8ac9b1841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-acab5aac72d2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     ]\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINCEPTIONV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_maps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-13cc95d68e96>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channel, features_map, classes)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINCEPTION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuxclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-13cc95d68e96>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mINCEPTION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuxclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        # Different projections\n",
        "        self.p1 = nn.Sequential(*[nn.Conv2d(in_channels, out_channels[0], kernel_size=1, padding=0, stride=1), self.relu])\n",
        "        self.p2 = nn.Sequential(*[nn.Conv2d(in_channels, out_channels[1], kernel_size=1, padding=0, stride=1), self.relu, nn.Conv2d(out_channels[1], out_channels[2], kernel_size=3, padding=1, stride=1), self.relu])\n",
        "        self.p3 = nn.Sequential(*[nn.Conv2d(in_channels, out_channels[3], kernel_size=1, padding=0, stride=1), self.relu, nn.Conv2d(out_channels[3], out_channels[4], kernel_size=5, padding=2, stride=1), self.relu])\n",
        "        self.p4 = nn.Sequential(*[nn.MaxPool2d(kernel_size=3, padding=1, stride=1), nn.Conv2d(in_channels, out_channels[5], kernel_size=1, padding=0, stride=1)])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.p1(x)\n",
        "        o2 = self.p2(x)\n",
        "        o3 = self.p3(x)\n",
        "        o4 = self.p4(x)\n",
        "\n",
        "        return torch.cat((o1,o2,o3,o4), axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWE7lV9ugvop",
        "outputId": "df4016e3-4558-4a7f-c89d-c422f6b58278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n",
            "torch.Size([1, 1000])\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AuxClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, classes):\n",
        "        super().__init__()\n",
        "        in_features = 4 * 4 * 128\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "        self.conv1x1 = nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=1, stride=1, padding=0)\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=in_features)\n",
        "        self.fc2 = nn.Linear(in_features=in_features, out_features=classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.relu(self.conv1x1(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.dropout(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ReBy34ixh4lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, in_depth=3, classes=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        in_channels = [192, 256, 480, 512, 512, 512, 528, 832, 832, 1024]\n",
        "        feature_maps = [[64, 96, 128, 16, 32, 32],\n",
        "                        [128, 128, 192, 32, 96, 64],\n",
        "                        [192, 96, 208, 16, 48, 64],\n",
        "                        [160, 112, 224, 24, 64, 64],\n",
        "                        [128, 128, 256, 24, 64, 64],\n",
        "                        [112, 144, 288, 32, 64, 64],\n",
        "                        [256, 160, 320, 32, 128, 128],\n",
        "                        [256, 160, 320, 32, 128, 128],\n",
        "                        [384, 192, 384, 48, 128, 128]\n",
        "                    ]\n",
        "\n",
        "        self.AuxClass1 = AuxClassifier(512, classes)\n",
        "        self.AuxClass2 = AuxClassifier(528,classes)\n",
        "        self.Blocks = nn.ModuleList([InceptionBlock(in_channels[i], feature_maps[i]) for i in range(len(feature_maps))])\n",
        "\n",
        "        # Rest of the model\n",
        "        self.Conv7k = nn.Conv2d(in_channels=in_depth, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
        "        self.Conv1k = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "        self.Conv3k = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1)\n",
        "        self.MaxPool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.LocalNorm = nn.LocalResponseNorm(size=5)\n",
        "        self.AvgPool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "        self.FC = nn.Linear(1024, classes)\n",
        "        self.Dropout = nn.Dropout(0.4)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        #print(next(iter(self.modules())))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        # x shape : [batch, 3, 224, 224]\n",
        "        x = self.relu(self.Conv7k(x))\n",
        "        x = self.LocalNorm(self.MaxPool(x))\n",
        "        x = self.relu(self.Conv1k(x))\n",
        "        x = self.LocalNorm(self.relu(self.Conv3k(x)))\n",
        "        x = self.MaxPool(x)\n",
        "        for i, block in enumerate(self.Blocks):\n",
        "            if i == 2 or i==7:\n",
        "                x = self.MaxPool(x)\n",
        "            elif i == 3:\n",
        "                outputs.append(self.AuxClass1(x))\n",
        "            elif i == 6:\n",
        "                outputs.append(self.AuxClass2(x))\n",
        "\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.Dropout(self.AvgPool(x))\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.FC(x)\n",
        "        outputs.append(x)\n",
        "        return outputs\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Inception = GoogLeNet()\n",
        "    outs = Inception(torch.rand(1, 3, 224, 224))\n",
        "    for out in outs:\n",
        "        print(out.shape)"
      ],
      "metadata": {
        "id": "2QDgMrYZh_KL",
        "outputId": "71f6fa3c-3846-4646-b835-1d531bdeff7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n",
            "torch.Size([1, 1000])\n",
            "torch.Size([1, 1000])\n"
          ]
        }
      ]
    }
  ]
}